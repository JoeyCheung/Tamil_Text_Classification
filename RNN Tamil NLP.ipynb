{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.layers import SpatialDropout1D\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom sklearn.feature_selection import RFE\nimport re\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tamil-nlp/tamil_news_train.csv')\ntest = pd.read_csv('/kaggle/input/tamil-nlp/tamil_news_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nnp.random.seed(7)\ntrain = train.drop_duplicates().reset_index(drop=True)\ntest = test.drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = stopwords.words('english')\n\ntrain.NewsInEnglish = train.NewsInEnglish.str.lower()\ntrain.NewsInEnglish = train.NewsInEnglish.str.replace('[^\\w\\s]',' ')\ntrain.NewsInEnglish = train.NewsInEnglish.str.replace('\\d+', ' ')\ntrain.NewsInEnglish = train.NewsInEnglish.str.replace(' txt', '')\ntrain.NewsInEnglish = train.NewsInEnglish.apply(lambda x: [item for item in [x] if item not in stop_words])\ncount = 0\nfor i in range(len(train.NewsInEnglish)):\n    train.NewsInEnglish[count] = train.NewsInEnglish[count][0].replace('  ', '')\n#     train.NewsInEnglish[count] = train.NewsInEnglish[count][0].split(' ')\n    count = count + 1\n    \ntrain.NewsInTamil = train.NewsInTamil.str.lower()\ntrain.NewsInTamil = train.NewsInTamil.str.replace('[^\\w\\s]',' ')\ntrain.NewsInTamil = train.NewsInTamil.str.replace('\\d+', ' ')\n\ntest.NewsInTamil = test.NewsInTamil.str.lower()\ntest.NewsInTamil = test.NewsInTamil.str.replace('[^\\w\\s]',' ')\ntest.NewsInTamil = test.NewsInTamil.str.replace('\\d+', ' ')\n\ntest.NewsInEnglish = test.NewsInEnglish.str.lower()\ntest.NewsInEnglish = test.NewsInEnglish.str.replace('[^\\w\\s]',' ')\ntest.NewsInEnglish = test.NewsInEnglish.str.replace('\\d+', ' ')\ntest.NewsInEnglish = test.NewsInEnglish.str.replace(' txt', '')\ntest.NewsInEnglish = test.NewsInEnglish.apply(lambda x: [item for item in [x] if item not in stop_words])    \ncount = 0\nfor i in range(len(test.NewsInEnglish)):\n    test.NewsInEnglish[count] = test.NewsInEnglish[count][0].replace('  ', '')\n#     test.NewsInEnglish[count] = test.NewsInEnglish[count][0].split(' ')\n    count = count + 1\n    \ntrain = train.append(test)\ndf = train\ndf.head()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Category.unique()\ndf.CategoryInTamil.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Category = df.Category.replace('world', 1)\ndf.Category = df.Category.replace('cinema', 2)\ndf.Category = df.Category.replace('tamilnadu', 3)\ndf.Category = df.Category.replace('india', 4)\ndf.Category = df.Category.replace('politics', 5)\ndf.Category = df.Category.replace('sports', 6)\n\ndf.CategoryInTamil = df.CategoryInTamil.replace(' உலகம்', 1)\ndf.CategoryInTamil = df.CategoryInTamil.replace(' சினிமா', 2)\ndf.CategoryInTamil = df.CategoryInTamil.replace(' தமிழ்நாடு', 3)\ndf.CategoryInTamil = df.CategoryInTamil.replace(' இந்தியா', 4)\ndf.CategoryInTamil = df.CategoryInTamil.replace(' அரசியல்', 5)\ndf.CategoryInTamil = df.CategoryInTamil.replace(' விளையாட்டு', 6)\n\ndf.Category.head()\ndf.CategoryInTamil.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 250\n# This is fixed.\nEMBEDDING_DIM = 100\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(df.NewsInEnglish.values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(df.NewsInEnglish.values)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(df.Category).values\nprint('Shape of label tensor:', Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(train_features, train_labels, epochs=5, batch_size=64,validation_split=0.2)\n# Final evaluation of the model\nmodel_pred_train = model.predict(train_features)\nmodel_pred_test = model.predict(test_features)\n# print(classification_report(test_labels,model_pred_test))\nprint('LSTM Recurrent Neural Network baseline: ' + str(roc_auc_score(train_labels, model_pred_train)))\nprint('LSTM Recurrent Neural Network: ' + str(roc_auc_score(test_labels, model_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 250\n# This is fixed.\nEMBEDDING_DIM = 100\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(df.NewsInEnglish.values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(df.NewsInEnglish.values)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(df.Category).values\nprint('Shape of label tensor:', Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(train_features, train_labels, epochs=5, batch_size=64,validation_split=0.2)\n# Final evaluation of the model\nmodel_pred_train = model.predict(train_features)\nmodel_pred_test = model.predict(test_features)\n# print(classification_report(test_labels,model_pred_test))\nprint('LSTM Recurrent Neural Network baseline: ' + str(roc_auc_score(train_labels, model_pred_train)))\nprint('LSTM Recurrent Neural Network: ' + str(roc_auc_score(test_labels, model_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show();\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}